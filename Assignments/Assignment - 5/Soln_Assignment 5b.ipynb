{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMWp3bQP-bhU"
   },
   "source": [
    "# Lab 5 - Classification :  k-NN and Naive Bayes (using sklearn libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **\"Pima Indians Diabetes Dataset from UCI Machine Learning Repository\"** for this question.It is a binary class dataset. Split the dataset into train(80%), validation(10%) and test sets(10%).\n",
    "\n",
    "Run k-Nearest neighbours for different k values. Choose your own subset of k (atleast 10) and choose the best value of k from this subset. In solving real-world problems, the values of k are chosen based on experience and hence it is a tunable hyperparameter. Select the k, using validation set, which returns the best accuracy score. Report accuracy score by performing k-NN on the test dataset using the chosen k value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of k: 1.000000, Accuracy on Validation set: 0.675325\n",
      "Value of k: 3.000000, Accuracy on Validation set: 0.753247\n",
      "Value of k: 7.000000, Accuracy on Validation set: 0.831169\n",
      "Value of k: 11.000000, Accuracy on Validation set: 0.818182\n",
      "Value of k: 13.000000, Accuracy on Validation set: 0.831169\n",
      "Value of k: 15.000000, Accuracy on Validation set: 0.818182\n",
      "Value of k: 17.000000, Accuracy on Validation set: 0.818182\n",
      "Value of k: 19.000000, Accuracy on Validation set: 0.818182\n",
      "Value of k: 21.000000, Accuracy on Validation set: 0.831169\n",
      "Value of k: 23.000000, Accuracy on Validation set: 0.831169\n",
      "Value of k: 25.000000, Accuracy on Validation set: 0.818182\n",
      "Value of k: 27.000000, Accuracy on Validation set: 0.818182\n",
      "Value of k: 29.000000, Accuracy on Validation set: 0.818182\n",
      "Value of k: 33.000000, Accuracy on Validation set: 0.844156\n",
      "Value of k: 47.000000, Accuracy on Validation set: 0.805195\n",
      "Value of k: 57.000000, Accuracy on Validation set: 0.818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "X = df\n",
    "y = df['Outcome']\n",
    "del X['Outcome']\n",
    "X_train, Xdash, y_train, ydash = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(Xdash, ydash, train_size=0.5, random_state=0)\n",
    "\n",
    "k = [1,3,7,11,13,15,17,19,21,23,25,27,29,33,47,57]\n",
    "error = []\n",
    "for i in range(len(k)):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k[i])\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_val)\n",
    "    error.append(np.mean(y_pred != y_val))\n",
    "    \n",
    "for i in range(len(k)):\n",
    "    print('Value of k: %f, Accuracy on Validation set: %f' %(k[i], 1- error[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set for k = 33:  0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=33)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "error = (np.mean(y_pred != y_test))\n",
    "print('Accuracy on test set for k = 33: ', 1-error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on test set for k = 33:  0.7532467532467533\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **\"Optical recognition of handwritten digits dataset\"** for this question. ** Download dataset from sklearn**. The dataset has 10 classes and 64 attributes (8x8 images). Visualise images from the dataset. Perform a train test split in the ratio 4:1. \n",
    "\n",
    "Naive Bayes - perform multiclass classification to classify the dataset into one of the ten classes. Experiment with the priors (Gaussian and Bernoulli) and report the best prior. Report the accuracies in terms of F1 scores and the confusion matrix (use sklearn functions for this too).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for BernoulliNB classifier 0.827099717314215\n",
      "F1 score for GaussianNB classifier 0.8529545573049961\n"
     ]
    }
   ],
   "source": [
    "b_clf = BernoulliNB()\n",
    "g_clf = GaussianNB()\n",
    "y_pred_ber = b_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(\"F1 score for BernoulliNB classifier\", (f1_score(y_test, y_pred_ber, average='weighted')))\n",
    "\n",
    "y_pred_gauss = g_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(\"F1 score for GaussianNB classifier\", (f1_score(y_test, y_pred_gauss, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for GaussianNB classifier \n",
      " [[30  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 34  1  0  0  0  1  1  6  4]\n",
      " [ 0  3 29  1  1  0  0  0  4  0]\n",
      " [ 0  1  1 24  0  0  0  4  3  1]\n",
      " [ 0  0  0  0 33  1  0  4  0  0]\n",
      " [ 0  0  0  0  0 27  0  1  0  0]\n",
      " [ 0  0  0  0  0  0 34  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 34  0  1]\n",
      " [ 0  2  0  0  0  1  0  0 33  0]\n",
      " [ 0  0  0  0  0  2  1  4  4 29]]\n",
      "\n",
      "\n",
      "Confusion Matrix for BernoulliNB classifier \n",
      " [[30  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 28  5  0  1  1  0  0  8  4]\n",
      " [ 0  1 31  3  0  0  0  0  3  0]\n",
      " [ 0  0  0 28  0  1  0  1  2  2]\n",
      " [ 0  0  0  0 35  0  0  3  0  0]\n",
      " [ 0  0  0  0  1 22  0  0  0  5]\n",
      " [ 0  0  0  0  0  0 34  0  0  0]\n",
      " [ 0  0  0  0  1  1  0 33  0  0]\n",
      " [ 0  1  0  1  0  0  0  0 29  5]\n",
      " [ 0  1  0  1  2  1  0  4  3 28]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix for GaussianNB classifier \\n\", confusion_matrix(y_test, y_pred_gauss))\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrix for BernoulliNB classifier \\n\", confusion_matrix(y_test, y_pred_ber))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian prior gave better results than Bernoulli prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab5_DataAnalytics.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
