{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analytics Lab (2nd Week)\n",
    "\n",
    "### Probability Distribution, Moments, Visualisation, Data Generation, Parameter Estimation, Hypothesis Testing, Correlation\n",
    "\n",
    "### Basic moments of one-dimensional data and visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement functions to compute median, mode, sample mean, sample variance, standard deviation of one-dimensional data \n",
    "\"without using numpy\". \n",
    "\n",
    "Example :\n",
    "data1 = np.array([1,2,3,4,5])\n",
    "\n",
    "data1_median = median(data1)\n",
    "\n",
    "data1_mode = mode(data1)\n",
    "\n",
    "data1_mean = mean(data1)\n",
    "\n",
    "data1_variance = variance(data1)\n",
    "\n",
    "data1_stddev = stddev(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the above for different one-dimensional datasets - data1.txt, data2.txt, data3.txt, data4.txt and store as data1_median, data2_median etc. Verify the results using the numpy built in functions for mean,stddev and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "\n",
    "# median\n",
    "\n",
    "# mode\n",
    "\n",
    "# variance\n",
    "\n",
    "#stddev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize all the datasets (1-4) separately using matplotlib scatter plot and histograms. \n",
    "\n",
    "1. Comment on initial observations of distributions. \n",
    "\n",
    "2. For each dataset, specify which descriptive statistics best describe the data.\n",
    "\n",
    "Example :\n",
    "\n",
    "data1 - mean\n",
    "\n",
    "data2 - mean\n",
    "\n",
    "data3 - mean\n",
    "\n",
    "data4 - mean\n",
    "\n",
    "Hints: If you want to plot a known distribution (Normal,Unifrom, Exponential etc) using matplotlib, define it as a function \n",
    "and plot it. For this, you need to know the formula of the chosen distribution. If you dont know the exact distribution \n",
    "of a dataset, plot it as a histogram and smooth the data by converting bin edges to centres. Using seaborn library: \n",
    "    Install seaborn library and use $\\texttt{distplot()}$ function to plot the distribution and verify the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization by scatter plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution fits a multimodal data. An appropriate measure of central tendency here is the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Distribution parameters and visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniform Distribution: A uniform distribution, also called a rectangular distribution, is a probability distribution that has constant probability. This distribution is defined by two parameters, a and b: a is the minimum and b is the maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula: \n",
    "\\begin{align*}\n",
    "f(x) = \\frac{1}{b-a} , a \\leq x \\leq b\n",
    "\\end{align*}\n",
    "Parameters:  $\\text{Mean} = \\frac{(a+b)}{2} ; \\text{Variance} = \\frac{1}{12(b-a)^2}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Distribution: The normal distribution is a probability function that describes how the values of a variable are distributed. It is a symmetric distribution where most of the observations cluster around the central peak and the probabilities for values further away from the mean taper off equally in both directions. For mean, $\\mu$ and standard deviation, $\\sigma$, the formula is given as\n",
    "\\begin{align*}\n",
    "f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the random.normal() method to get a Normal Data Distribution.\n",
    "\n",
    "It has three parameters:\n",
    "\n",
    "loc - (Mean) where the peak of the bell exists.\n",
    "\n",
    "scale - (Standard Deviation) how flat the graph distribution should be.\n",
    "\n",
    "size - The shape of the returned array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a normal distribution of mean = 3 and standard deviation = 1. \n",
    "1. Find $P(x\\leq3)$ from the given distribution. \n",
    "2. Find the probability that $P(3\\lt x\\leq5)$ drawn from the given distribution. \n",
    "Write a function to estimate the above cumulative distribution function of a normal distribution. Verify the same.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Find  p(x<3)  from the given distribution\n",
    "\n",
    "# 2. Find the probability that p(3<x<=5)  drawn from the given distribution\n",
    "\n",
    "# Function for estimating cdf\n",
    "\n",
    "def estimateCDF(x, a, b):\n",
    "    \"\"\"\n",
    "    PARAMETERS:\n",
    "    x : input 1D data\n",
    "    a, b: data points at which cdf is to be estimated \n",
    "    \n",
    "    RETURNS:\n",
    "    cdf : cumulative distibution values s.t. P(a<x<=b)  \n",
    "    \"\"\"\n",
    "    \n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood Estimation for normal distribution : \n",
    "A method of estimating the parameters of a distribution by maximizing a likelihood function, so that under the assumed statistical model the observed data is most probable. For normal distribution, $f(x,\\mu,\\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}$, the goal is to determine $\\mu$ and $\\sigma$ for our data so that we can match our data to its most likely Gaussian bell curve. The estimated mean, $\\hat{\\mu}$ for normal distribution is  $\\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^nx_i$ and the estimated standard deviation is $\\hat{\\sigma} = \\sqrt{ \\frac{1}{n}\\sum_{i=1}^n(x_i-\\mu)^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that data1 has been sampled from normal distribution with unknown mean and standard deviation of 2, calculate $95\\%$ confidence interval of data1_mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will fit data to a standard distribution.\n",
    "\n",
    "Normal distribution \n",
    "\"DataSet1.txt\" is to be fitted to normal distribution. Complete the function fitNormal() to estimate parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitNormal(x):\n",
    "    \"\"\"\n",
    "    PARAMETERS:\n",
    "    x : input 1D data\n",
    "    \n",
    "    RETURNS:\n",
    "    mu : mean of distribution\n",
    "    sig : standard deviation of distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    return [mu, sig]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the file \"DataSet1.txt\" into a variable $\\texttt{data1}$. Also plot a histogram of the same. Then pass it to $\\texttt{fitNormal()}$ to estimate parameters. Generate your own data using estimated parameters and plot the distribution. Use $\\texttt{numpy.linspace()}$ to generate 1000 points in the range of $\\texttt{data1}$. The probabilities are estimated from Gaussian distribution formula. Make a lineplot in the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datafile\n",
    "\n",
    "# Plot histogram of input data\n",
    "\n",
    "# Fit data to normal distribution\n",
    "\n",
    "# Generate data using estimated parameters for visualization and plot the same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"DataSet2.txt\" is to be fitted to uniform distribution. Complete the function fitUniform() to estimate parameters. Generate and plot data as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitUniform(x):\n",
    "    \"\"\"\n",
    "    PARAMETERS:\n",
    "    x : input 1D data\n",
    "    \n",
    "    RETURNS:\n",
    "    a : minimum value of distribution\n",
    "    b : maximum value of distribution\n",
    "    \"\"\"\n",
    " \n",
    "    return [a, b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the file \"DataSet2.txt\" into a variable \"data2\". Also plot a histogram of the same. Then pass it to $\\texttt{fitUniform()}$ to estimate parameters. Generate your own data using estimated parameters and plot the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datafile\n",
    "\n",
    "# Plot histogram of input data\n",
    "\n",
    "# Fit data to normal distribution\n",
    "\n",
    "# Generate data using estimated parameters for visualization and plot the same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "In this section you are required to measure correlation between two variables. The dataset \"**AirQualityData.csv**\" contains daily readings of $\\text{PM}_{10}$ and $O_3$ concentration in air along with temperature readings. To verify if the variation concentration of any of these pollutants is associated with temperature changes, measure the correlation between temperature and each of these pollutants. Complete the function $\\texttt{correlationCoeff()}$ below that measures the correlation coefficient between two given time-series data. For a given n two data sets x and y, the Pearson coefficient formula is given as\n",
    "\n",
    "\\begin{align*}\n",
    "    r_{xy} = \\frac{cov(X,Y)}{\\sigma(X)\\cdot \\sigma(Y)}\n",
    "\\end{align*}\n",
    "$cov(X,Y) = \\frac{\\Sigma_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y})}{n-1}; \\\\ $ \n",
    "$\\sigma(X), \\sigma(Y)$ are respective standard deviations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correlationCoeff(x, y):\n",
    "    \"\"\"\n",
    "    PARAMETERS:\n",
    "    x : input 1D data\n",
    "    y : input 1D data\n",
    "    \n",
    "    RETURNS:\n",
    "    est : coefficient value\n",
    "    \"\"\"\n",
    "    \n",
    "    return est\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the file \"AirQualityData.csv\" . Ignoring the \"date\" column, read columns \"temp\", \"pm10\" and \"o3\" as the dataframe as pass them to the function $\\texttt{correlationCoeff()}$ to estimate seperately the effect of \"pm10\" on \"temp\" and \"o3\" on \"temp\". Which of the pollutants has a greater impact on temperature? Compare the value that you get from the above function with the python built in function $\\texttt{df.corr()}$ . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datafile\n",
    "\n",
    "# Estimate correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing and Confidence Interval "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P Value: A p-value for a statistical model is the probability that when the null hypothesis is true, the statistical summary is equal to or greater than the actual observed results. This is also termed ‘probability value’ or ‘asymptotic significance’. The null hypothesis states that two measured phenomena experience no relationship to each other. We denote this as H or H0. If one or more of these probabilities turn out to be less than or equal to α, the level of significance, we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: One such null hypothesis can be that the number of hours spent in the office affects the amount of salary paid. For a significance level of 5%, if the p-value falls lower than 5%, the null hypothesis is invalidated. Then it is discovered that the number of hours you spend in your office will not affect the amount of salary you will take home. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T Test: Such a test tells us whether a sample of numeric data strays or differs significantly from the population. It also talks about two samples- whether they’re different. In other words, it gives us the probability of difference between populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install scipy library \n",
    "# import scipy.stats\n",
    "# Use the function stats.ttest_ind() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KS Test: KS Test in Python Statistics: This is the Kolmogorov-Smirnov test. It lets us test the hypothesis that the sample is a part of the standard t-distribution. Let’s take an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the function stats.kstest(x,y) to compare the two distributions x and y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example\n",
    "#Generate 10,000 random data from a normal distribution of mean 0 and standard 1 with a random seed value of 10.\n",
    "# Use KS test to compare the generated data to a normal distribution using kstest\n",
    "#if the p-value is less than 0.05 or 5% (for a 95% confidence level), then the null hypothesis is rejected, \n",
    "#which means the generated data is not from the normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example \n",
    "# Generate 10,000 random data from a poisson distribution of lambda = 5\n",
    "# Generate 7,000 random data from a poisson distribution of lambda = 7\n",
    "# compare the mean of the two data sets using t test with a confidence level of 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
